/**
 * ğŸ”Œ Ù…Ø«Ø§Ù„ ØªØ·Ø¨ÙŠÙ‚ÙŠ - Ø¯Ù…Ø¬ Hybrid LLM Ù…Ø¹ tRPC Router
 * 
 * Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙŠÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø¯Ù…Ø¬ Ù†Ø¸Ø§Ù… Hybrid LLM Ù…Ø¹ Ø§Ù„Ù€ routers Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
 * ÙÙŠ Ù…Ø´Ø±ÙˆØ¹ Ø±Ù‚ÙŠÙ… AI 966
 */

import { router, publicProcedure } from './server/_core/trpc';
import { hybridLLM, TaskType, Priority, LLMProvider } from './server/_core/llm-hybrid';
import { z } from 'zod';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“Š Schema Definitions
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const GeneratePromptInput = z.object({
  userInput: z.string().min(10, 'Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹'),
  usageType: z.enum([
    'tweet',
    'code',
    'article',
    'teaching',
    'exam',
    'crypto'
  ]),
  options: z.object({
    tone: z.string().optional(),
    examples: z.boolean().optional(),
    bulletPoints: z.boolean().optional(),
    length: z.enum(['short', 'medium', 'long']).optional(),
    complexity: z.enum(['simple', 'moderate', 'advanced']).optional(),
  }).optional(),
  // Ø®ÙŠØ§Ø±Ø§Øª LLM
  llmOptions: z.object({
    priority: z.enum(['speed', 'quality', 'cost', 'balanced']).optional(),
    preferredProvider: z.enum(['gemini', 'deepseek', 'claude', 'gpt4', 'humain']).optional(),
  }).optional()
});

const AnalyzePromptInput = z.object({
  prompt: z.string().min(20, 'Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªØ­Ù„ÙŠÙ„'),
  llmOptions: z.object({
    priority: z.enum(['speed', 'quality', 'cost', 'balanced']).optional(),
  }).optional()
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤– Enhanced App Router with Hybrid LLM
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const enhancedAppRouter = router({
  
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 1ï¸âƒ£ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù…Ø­Ø³Ù‘Ù† (Enhanced)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  generatePrompt: publicProcedure
    .input(GeneratePromptInput)
    .mutation(async ({ input }) => {
      const { userInput, usageType, options, llmOptions } = input;
      
      // Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
      const systemPrompt = buildSystemPrompt(userInput, usageType, options);
      
      // ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
      const taskType: TaskType = 'generate_prompt';
      const priority: Priority = llmOptions?.priority || 'balanced';
      const preferredProvider = llmOptions?.preferredProvider;
      
      console.log(`ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±ÙˆÙ…Ø¨Øª - Ø§Ù„Ù…Ù‡Ù…Ø©: ${taskType}, Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: ${priority}`);
      
      // Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù€ Hybrid LLM
      const response = await hybridLLM.sendRequest({
        prompt: systemPrompt,
        taskType,
        priority,
        preferredProvider,
        maxTokens: getMaxTokensByLength(options?.length),
        temperature: getTemperatureByComplexity(options?.complexity)
      });
      
      if (!response.success) {
        throw new Error(`ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª: ${response.error}`);
      }
      
      console.log(`âœ… Ù†Ø¬Ø­ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: ${response.provider}, Ø§Ù„ØªÙƒÙ„ÙØ©: $${response.cost.toFixed(6)}`);
      
      return {
        generatedPrompt: response.content,
        metadata: {
          provider: response.provider,
          model: response.model,
          tokensUsed: response.tokensUsed,
          cost: response.cost,
          responseTime: response.responseTime
        }
      };
    }),
  
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 2ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Enhanced)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  analyzePrompt: publicProcedure
    .input(AnalyzePromptInput)
    .mutation(async ({ input }) => {
      const { prompt, llmOptions } = input;
      
      const analysisPrompt = `Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨ØªØ§Øª. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„:

"${prompt}"

Ù‚Ø¯Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:
1. **Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ø§Ù…**: Ø¯Ø±Ø¬Ø© Ù…Ù† 100
2. **Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©**: Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ø¹Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª ÙØ¹Ø§Ù„Ø§Ù‹ØŸ
3. **Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù**: Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠÙ†Ù‚ØµÙ‡ Ø£Ùˆ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†ØŸ
4. **Ø§Ù„ÙˆØ¶ÙˆØ­**: Ù‡Ù„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙ‡ÙˆÙ…ØŸ (Ø¯Ø±Ø¬Ø© Ù…Ù† 10)
5. **Ø§Ù„Ø´Ù…ÙˆÙ„ÙŠØ©**: Ù‡Ù„ ÙŠØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ (Ø¯Ø±Ø¬Ø© Ù…Ù† 10)
6. **Ø§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„ØªÙ†ÙÙŠØ°**: Ù‡Ù„ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØªÙ†ÙÙŠØ°Ù‡ Ø¨Ø³Ù‡ÙˆÙ„Ø©ØŸ (Ø¯Ø±Ø¬Ø© Ù…Ù† 10)
7. **Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†**: 3-5 Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¹Ù…Ù„ÙŠØ© Ù…Ø­Ø¯Ø¯Ø©

Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ JSON Ù„Ù„Ù†ØªÙŠØ¬Ø©.`;
      
      const priority: Priority = llmOptions?.priority || 'quality'; // Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙŠØ­ØªØ§Ø¬ Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©
      
      console.log(`ğŸ” ØªØ­Ù„ÙŠÙ„ Ø¨Ø±ÙˆÙ…Ø¨Øª - Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: ${priority}`);
      
      const response = await hybridLLM.sendRequest({
        prompt: analysisPrompt,
        taskType: 'analyze_prompt',
        priority,
        maxTokens: 3000,
        temperature: 0.3 // ØªØ­Ù„ÙŠÙ„ ÙŠØ­ØªØ§Ø¬ Ø¯Ù‚Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø¥Ø¨Ø¯Ø§Ø¹
      });
      
      if (!response.success) {
        throw new Error(`ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª: ${response.error}`);
      }
      
      console.log(`âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„ - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: ${response.provider}`);
      
      return {
        analysis: response.content,
        metadata: {
          provider: response.provider,
          model: response.model,
          tokensUsed: response.tokensUsed,
          cost: response.cost,
          responseTime: response.responseTime
        }
      };
    }),
  
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 3ï¸âƒ£ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  getLLMStats: publicProcedure
    .query(() => {
      const stats = hybridLLM.getUsageStats();
      const available = hybridLLM.getAvailableProviders();
      
      // Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ§Øª
      const totals = Object.values(stats).reduce(
        (acc, curr) => ({
          requests: acc.requests + curr.requests,
          tokens: acc.tokens + curr.tokens,
          cost: acc.cost + curr.cost
        }),
        { requests: 0, tokens: 0, cost: 0 }
      );
      
      return {
        byProvider: stats,
        totals,
        availableProviders: available.map(p => ({
          provider: p.provider,
          model: p.config.model,
          enabled: p.config.enabled
        }))
      };
    }),
  
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 4ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  testProviders: publicProcedure
    .input(z.object({
      prompt: z.string(),
      providers: z.array(z.enum(['gemini', 'deepseek', 'claude', 'gpt4', 'humain'])).optional()
    }))
    .mutation(async ({ input }) => {
      const { prompt, providers } = input;
      
      const available = hybridLLM.getAvailableProviders();
      const providersToTest = providers || available.map(p => p.provider);
      
      console.log(`ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ${providersToTest.length} Ù†Ù…Ø§Ø°Ø¬...`);
      
      const results = await Promise.allSettled(
        providersToTest.map(provider =>
          hybridLLM.sendRequest({
            prompt,
            taskType: 'general',
            preferredProvider: provider,
            maxTokens: 500
          })
        )
      );
      
      const comparison = results.map((result, index) => {
        if (result.status === 'fulfilled') {
          const response = result.value;
          return {
            provider: providersToTest[index],
            success: response.success,
            content: response.content.substring(0, 200) + '...',
            tokensUsed: response.tokensUsed,
            cost: response.cost,
            responseTime: response.responseTime,
            model: response.model
          };
        } else {
          return {
            provider: providersToTest[index],
            success: false,
            error: result.reason?.message || 'ÙØ´Ù„ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'
          };
        }
      });
      
      return {
        prompt,
        comparison,
        summary: {
          tested: providersToTest.length,
          successful: comparison.filter(c => c.success).length,
          failed: comparison.filter(c => !c.success).length
        }
      };
    }),
  
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 5ï¸âƒ£ ØªØ±Ø¬Ù…Ø© Ø°ÙƒÙŠØ©
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  translateText: publicProcedure
    .input(z.object({
      text: z.string(),
      targetLanguage: z.enum(['ar', 'en']),
      preserveFormatting: z.boolean().optional()
    }))
    .mutation(async ({ input }) => {
      const { text, targetLanguage, preserveFormatting } = input;
      
      const translatePrompt = `ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ ${targetLanguage === 'ar' ? 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' : 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'}:

${text}

${preserveFormatting ? 'Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£ØµÙ„ÙŠ (ÙÙ‚Ø±Ø§ØªØŒ Ù†Ù‚Ø§Ø·ØŒ Ø¥Ù„Ø®).' : ''}`;
      
      const response = await hybridLLM.sendRequest({
        prompt: translatePrompt,
        taskType: 'translate',
        priority: 'quality', // Ø§Ù„ØªØ±Ø¬Ù…Ø© ØªØ­ØªØ§Ø¬ Ø¬ÙˆØ¯Ø©
        maxTokens: 2000
      });
      
      if (!response.success) {
        throw new Error('ÙØ´Ù„Øª Ø§Ù„ØªØ±Ø¬Ù…Ø©');
      }
      
      return {
        translatedText: response.content,
        metadata: {
          provider: response.provider,
          sourceLanguage: targetLanguage === 'ar' ? 'en' : 'ar',
          targetLanguage,
          tokensUsed: response.tokensUsed
        }
      };
    })
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ› ï¸ Helper Functions
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª
 */
function buildSystemPrompt(
  userInput: string,
  usageType: string,
  options?: any
): string {
  const usageTypeMap: Record<string, string> = {
    tweet: 'ØªØºØ±ÙŠØ¯Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¹Ù„Ù‰ ØªÙˆÙŠØªØ±',
    code: 'ÙƒØªØ§Ø¨Ø© ÙˆØ´Ø±Ø­ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©',
    article: 'ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø·ÙˆÙŠÙ„',
    teaching: 'Ø´Ø±Ø­ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©',
    exam: 'Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø©',
    crypto: 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª'
  };
  
  let prompt = `Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ${usageTypeMap[usageType] || 'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø©'}.

Ø§Ù„Ù…Ù‡Ù…Ø©: Ù‚Ù… Ø¨ØªØ­Ø³ÙŠÙ† ÙˆØªØ·ÙˆÙŠØ± Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ØªØ§Ù„ÙŠ Ù„ÙŠØµØ¨Ø­ Ø£ÙƒØ«Ø± Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆÙØ¹Ø§Ù„ÙŠØ©:

"${userInput}"

`;

  if (options?.tone) {
    prompt += `\nØ§Ù„Ù†Ø¨Ø±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: ${options.tone}`;
  }
  
  if (options?.examples) {
    prompt += `\nÙ‚Ù… Ø¨ØªØ¶Ù…ÙŠÙ† Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© ØªÙˆØ¶ÙŠØ­ÙŠØ©.`;
  }
  
  if (options?.bulletPoints) {
    prompt += `\nØ§Ø³ØªØ®Ø¯Ù… Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù†Ø¸Ù…Ø©.`;
  }
  
  if (options?.complexity) {
    const complexityMap = {
      simple: 'Ø¨Ø³ÙŠØ· ÙˆÙ…Ø¨Ø§Ø´Ø±',
      moderate: 'Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ¹Ù‚ÙŠØ¯',
      advanced: 'Ù…ØªÙ‚Ø¯Ù… ÙˆØªÙØµÙŠÙ„ÙŠ'
    };
    prompt += `\nÙ…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: ${complexityMap[options.complexity]}`;
  }
  
  prompt += `\n\nÙ‚Ø¯Ù… Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù…Ø­Ø³Ù‘Ù† ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ù…Ù‚Ø¯Ù…Ø§Øª Ø£Ùˆ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.`;
  
  return prompt;
}

/**
 * ØªØ­Ø¯ÙŠØ¯ max tokens Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
 */
function getMaxTokensByLength(length?: string): number {
  switch (length) {
    case 'short':
      return 500;
    case 'long':
      return 3000;
    case 'medium':
    default:
      return 1500;
  }
}

/**
 * ØªØ­Ø¯ÙŠØ¯ temperature Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
 */
function getTemperatureByComplexity(complexity?: string): number {
  switch (complexity) {
    case 'simple':
      return 0.5; // Ø£Ù‚Ù„ Ø¥Ø¨Ø¯Ø§Ø¹ØŒ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
    case 'advanced':
      return 0.9; // Ø£ÙƒØ«Ø± Ø¥Ø¨Ø¯Ø§Ø¹ ÙˆØªÙ†ÙˆØ¹
    case 'moderate':
    default:
      return 0.7; // Ù…ØªÙˆØ§Ø²Ù†
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“¤ Export
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export type EnhancedAppRouter = typeof enhancedAppRouter;
